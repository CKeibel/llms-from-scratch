{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e394571-c94a-4629-b773-39b5fc5ef544",
   "metadata": {},
   "source": [
    "# Decoder (GPT type model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a00b75-5eac-4c0c-8cf4-f3a6f35ff63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoConfig, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8150e80-0e05-4fb5-a461-c89a3d559ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"openai-community/gpt2\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.38.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"openai-community/gpt2\"\n",
    "gpt2_config = AutoConfig.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "gpt2_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcdd407-125c-481a-9783-819cef1dbdf3",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8b5427-448e-4e16-952e-a1788abe4163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'Ä Transformers', '!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Hello Transformers!\"\n",
    "\n",
    "# Tokenized input\n",
    "tokenizer.tokenize(input_text, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c659bab1-613f-45f0-872f-6dacf777bb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496, 39185,     0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token ids\n",
    "tokenized_input = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dff35f3-e53d-46a4-80e6-35f89197d4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15496 -> Hello\n",
      "39185 ->  Transformers\n",
      "0 -> !\n"
     ]
    }
   ],
   "source": [
    "# Corresponding ids to tokens\n",
    "for i in tokenized_input[0]:\n",
    "    print(f\"{i} -> {tokenizer.decode(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b6a892-6b49-43cc-b68b-d7030aef6f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 50257\n",
      "Hidden/Embedding size: 768\n",
      "Embedding matrix: Embedding(50257, 768)\n"
     ]
    }
   ],
   "source": [
    "token_embed = nn.Embedding(gpt2_config.vocab_size, gpt2_config.n_embd)\n",
    "\n",
    "print(f\"Vocabulary size: {gpt2_config.vocab_size}\")\n",
    "print(f\"Hidden/Embedding size: {gpt2_config.n_embd}\")\n",
    "print(f\"Embedding matrix: {token_embed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883f5c58-5f18-435e-9591-5a8f75ccd9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized shape: torch.Size([1, 3])\n",
      "Embedded shape: torch.Size([1, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "# embedd input tokens\n",
    "token_embeddings = token_embed(tokenized_input)\n",
    "print(f\"Tokenized shape: {tokenized_input.shape}\")\n",
    "print(f\"Embedded shape: {token_embeddings.shape}\") # batch_size, input_length, embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247b37d1-0490-4462-a6cf-47e5a9ed07d1",
   "metadata": {},
   "source": [
    "## Scaled dot-product attention (self-attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa1c6e7-17e3-4fe5-9876-2e1642e81e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(key, query, value, mask):\n",
    "    # scaling factor\n",
    "    dim_k = key.size(-1)\n",
    "    # (seq_len x embed_dim)*(embed_dim x seq_dim)=(seq_len X seq_len)\n",
    "    scores = torch.bmm(key, query.transpose(1, 2)) / sqrt(dim_k) \n",
    "    # masked fill (seq_len x seq_len)\n",
    "    scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    weigths = F.softmax(scores, dim=-1)\n",
    "    # (seq_len x seq_len)*(seq_len x embed_dim)=(seq_len x embed_dim)\n",
    "    return torch.bmm(weigths, value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae5c809-336c-4f45-bfb6-497e0d8b5cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask\n",
    "seq_len = token_embeddings.size(1)\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0)\n",
    "\n",
    "outputs = scaled_dot_product_attention(token_embeddings, token_embeddings, token_embeddings, mask)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a214f0-f9e1-4fd2-a054-8b6242715eb2",
   "metadata": {},
   "source": [
    "## Multi-headed attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7367b8-2445-4245-8219-845bb8683712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.key = nn.Linear(embed_dim, head_dim)\n",
    "        self.query = nn.Linear(embed_dim, head_dim)\n",
    "        self.value = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        seq_len = inputs.size(1)\n",
    "        mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0) # (seq_len x seq_len)\n",
    "        return scaled_dot_product_attention(\n",
    "            self.key(inputs), self.query(inputs), self.value(inputs), mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca566514-78aa-4715-865f-c13a3c3da1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = config.n_head\n",
    "        self.embed_dim = config.n_embd\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "        self.heads = nn.ModuleList([AttentionHead(self.embed_dim, self.head_dim) for _ in range(self.num_heads)])\n",
    "        self.output_linear = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = torch.cat([h(inputs) for h in self.heads],dim=-1)\n",
    "        return self.output_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dbc4d0f-4fbc-4df5-906b-460d323a41b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head_attn = MultiHeadAttention(gpt2_config)\n",
    "outputs = multi_head_attn(token_embeddings)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696b361-98d3-4767-aff6-8292154fa350",
   "metadata": {},
   "source": [
    "## Position-wise feed-froward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2509c0-9ae5-488f-a5e4-761bf3ec79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear_1 = nn.Linear(config.n_embd, 4*config.n_embd)\n",
    "        self.linear_2 = nn.Linear(4*config.n_embd, config.n_embd)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = self.gelu(x)\n",
    "        x = self.linear_2(x)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b94546-3dc7-463d-8f9e-e9a7ca003afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = PositionwiseFeedForward(gpt2_config)\n",
    "outputs = ff(token_embeddings)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e3ac2-8e14-462f-8b7e-1386d1371e6c",
   "metadata": {},
   "source": [
    "## Decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4690b0-1bd9-4943-afe9-c6df0267c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.layer_norm_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.layer_norm_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.attention = MultiHeadAttention(config)\n",
    "        self.ff = PositionwiseFeedForward(config)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Pre layer normalization:\n",
    "        \n",
    "        inputs -+-> norm_1 -> attention -- + -- +-> norm_2 -> feed-forward -- + --> outputs\n",
    "                +---- skip-connection -----+    +------ skip-connection ------+\n",
    "        \"\"\"\n",
    "        # block 1\n",
    "        norm_1 = self.layer_norm_1(inputs)\n",
    "        x = inputs + self.attention(norm_1)\n",
    "\n",
    "        # block 2\n",
    "        norm_2 = self.layer_norm_2(x)\n",
    "        x = x + self.ff(norm_2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f298f3b7-9d16-4ae2-b951-36fb3d73ce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_layer = DecoderLayer(gpt2_config)\n",
    "outputs = decoder_layer(token_embeddings)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd427a2-ca68-4a0a-a983-31ac96d099f3",
   "metadata": {},
   "source": [
    "## Positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b06e600-afde-461a-aa2a-5d57d37ba1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.token_embed = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.position_embed = nn.Embedding(config.n_positions, config.n_embd)\n",
    "        self.layer_norm = nn.LayerNorm(config.n_embd, eps=config.layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # create position ids\n",
    "        seq_len = inputs.size(1)\n",
    "        position_ids = torch.arange(seq_len, dtype=torch.long).unsqueeze(0) # seq_len\n",
    "\n",
    "        # embeddings\n",
    "        token_embeddings = self.token_embed(inputs) # embed_dim\n",
    "        position_embeddings = self.position_embed(position_ids) # embed_dim\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        return self.dropout(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd1f92aa-92b6-429f-a408-0bea57922a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = Embeddings(gpt2_config)\n",
    "outputs = embed(tokenized_input)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7ed46-befd-40ed-b590-a6d44fa500e6",
   "metadata": {},
   "source": [
    "## Transfomer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f1e08ed-cb10-4e40-a648-acb090ce4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = Embeddings(config)\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(config) for _ in range(config.n_layer)])\n",
    "        self.output_linear = nn.Linear(config.n_embd, config.vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f81b8599-6762-49e2-a434-d5935f1cc654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 50257])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(gpt2_config)\n",
    "outputs = decoder(tokenized_input)\n",
    "outputs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llms",
   "language": "python",
   "name": ".llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
